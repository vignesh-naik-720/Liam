# AI Voice Agent : Liam

Liam is a **real-time voice-based conversational AI** that:
- Listens to your voice.
- Transcribes it into text using **AssemblyAI**.
- Generates a response using **Google Gemini AI**.
- Converts the AI's response into speech using **Murf AI** (with a gTTS fallback).

Itâ€™s designed for an **auto-loop conversation** where the bot and the user can talk continuously.

---

## ğŸ“‚ Project Structure
```plaintext
project_root/
â”œâ”€â”€ app.py               
â”œâ”€â”€ config.py            
â”œâ”€â”€ services/ 
â”‚   â”œâ”€â”€ stt_service.py   
â”‚   â”œâ”€â”€ tts_service.py   
â”‚   â””â”€â”€ llm_service.py   
â”œâ”€â”€ utils/               
â”‚   â””â”€â”€ fallback.py
â”œâ”€â”€ frontend/            
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ speaker.png
â”‚   â””â”€â”€ fallback.mp3
â”œâ”€â”€ uploads/             # Uploaded audio
â”œâ”€â”€ generated_audio/     # Generated audio output
â””â”€â”€ .env                

```

---

## ğŸ›  Technologies Used

**Frontend**
- HTML5, CSS3, JavaScript (Vanilla)
- Web Audio API & `MediaRecorder` API
- Lottie animations

**Backend**
- [Flask](https://flask.palletsprojects.com/) â€” Web framework
- [AssemblyAI](https://www.assemblyai.com/) â€” Speech-to-text
- [Google Gemini AI](https://ai.google.dev/) â€” Large Language Model
- [Murf AI](https://murf.ai/) â€” Text-to-speech
- [gTTS](https://pypi.org/project/gTTS/) â€” Fallback TTS

**Other**
- [python-dotenv](https://pypi.org/project/python-dotenv/) for environment variables
- `requests` for external API calls

---

## ğŸ— Architecture

```mermaid
flowchart LR
    UserVoice[ğŸ™ User speaks] -->|Audio| Flask[Flask Backend]
    Flask -->|Audio File| AssemblyAI[AssemblyAI STT]
    AssemblyAI -->|Transcribed Text| Gemini[Google Gemini AI]
    Gemini -->|Generated Text| MurfAI[Murf AI TTS]
    MurfAI -->|Audio URLs| Frontend[Web Frontend]
    Frontend -->|Plays Audio| UserVoice
    Flask -->|Fallback Audio via gTTS| Frontend
```
âœ¨ Features

ğŸ™ Continuous conversation loop (auto-listen after bot finishes speaking)

ğŸ”„ Session history tracking per conversation

ğŸ›¡ Fallback voice if APIs fail (gTTS-generated)

ğŸ“œ Chat history retrieval via /agent/history/<session_id>

ğŸ’¡ Minimalistic UI with Lottie animations and glowing mic button

âš¡ Concurrent-safe chat storage with thread locking

ğŸš€ Getting Started
1ï¸âƒ£ Clone the repository
git clone https://github.com/vignesh-naik-720/Liam
cd Liam

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt


requirements.txt should include:

Flask
requests
python-dotenv
assemblyai
google-generativeai
gTTS

3ï¸âƒ£ Set environment variables

Create a .env file in the root:
```
MURF_API_KEY=your_murf_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
GEMINI_API_KEY=your_google_gemini_api_key
```

Get your API keys from:
```plaintext
Murf AI â†’ https://murf.ai/

AssemblyAI â†’ https://www.assemblyai.com/

Google Gemini â†’ https://ai.google.dev/
```
4ï¸âƒ£ Run the API server
python app.py


The Flask server runs at:

http://127.0.0.1:8000

5ï¸âƒ£ Open the frontend

Open frontend/index.html in your browser
(or visit the Flask root / if serving static files via Flask).

ğŸ“¡ API Endpoints
```plaintext
Method	Endpoint	Description
POST	/agent/chat/<session_id>	Upload audio file, returns transcription, LLM output, and TTS audio URLs
GET	/agent/history/<session_id>	Retrieve conversation history
GET	/uploads/<filename>	Serve uploaded audio files
GET	/fallback.mp3	Serve fallback audio
```
âš  Notes

Make sure microphone permissions are enabled in the browser.

If Murf AI fails, the system automatically falls back to gTTS.

Large text replies are chunked for TTS (max 3000 chars each).

The conversation context is capped at the last 20 messages per session.

ğŸ‘¨â€ğŸ’» Author

Developed by Vignesh Naik
